{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDe7DsPWmEBV"
   },
   "source": [
    "<h1>1장 대규모 언어 모델 소개</h1>\n",
    "<i>흥미진진한 언어 AI 분야를 탐험합니다.</i>\n",
    "\n",
    "\n",
    "<a href=\"https://github.com/rickiepark/handson-llm\"><img src=\"https://img.shields.io/badge/GitHub%20Repository-black?logo=github\"></a>\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rickiepark/handson-llm/blob/main/chapter01.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "이 노트북은 <[핸즈온 LLM](https://tensorflow.blog/handson-llm/)> 책 1장의 코드를 담고 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "<a href=\"https://tensorflow.blog/handson-llm/\">\n",
    "<img src=\"https://tensorflow.blog/wp-content/uploads/2025/05/ed95b8eca688ec98a8_llm.jpg\" width=\"350\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buDa1--HJsJB"
   },
   "source": [
    "---\n",
    "\n",
    "💡 **NOTE**: 이 노트북의 코드를 실행하려면 GPU를 사용하는 것이 좋습니다. 구글 코랩에서는 **런타임 > 런타임 유형 변경 > 하드웨어 가속기 > T4 GPU**를 선택하세요.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gioKeW2nK2zX",
    "outputId": "9ad210e5-e4e1-4216-9f7f-5e6f9346d5b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.48.3\n",
      "  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (0.32.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.3) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.3) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.3) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.3) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.3) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.3) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.48.3) (2025.4.26)\n",
      "Downloading transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.52.4\n",
      "    Uninstalling transformers-4.52.4:\n",
      "      Successfully uninstalled transformers-4.52.4\n",
      "Successfully installed transformers-4.48.3\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.48.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXp09JFsFBXi"
   },
   "source": [
    "# Phi-3\n",
    "\n",
    "첫 번째 단계로 빠른 추론을 위해 모델을 GPU에 로드합니다. 모델과 토크나이저를 각각 로드합니다(항상 이렇게 할 필요는 없습니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 631,
     "referenced_widgets": [
      "e57df314d9974eff8c8c1264c6a66039",
      "e4600365a774415d901fb7cb0a4dddbd",
      "ea017c16035d412a9567315e6331b2ea",
      "e9431a0fbdaa411f9877b7d5add6a10a",
      "22a391e3f89d478185118ec5cbd99f55",
      "2edf039951924fc99951c7d7b136a272",
      "01b16d59f82c465cac80356bfd82207c",
      "c3db15b44ec84113a5b5867a489466a4",
      "60a94bc385cb4274a35cb89cb3d6900b",
      "91aa14446f0942d38bb414950d812ac7",
      "c7b56b1c83c74a92aa5cd69106fc9c9e",
      "8cc1760009fb414981b7de9ebac6eb07",
      "baf23ee23a3e486fa6da2a2bfc465acd",
      "58d8bb41a12d4246927afc38b65446ec",
      "fe6140a73bfb4ce5aab5b9932f73260b",
      "bc4213cf937e4b318404f22f1e6ee122",
      "85b503816879425fad5a0585272a2901",
      "21e9320d952e499e90cdf3a9531c1b45",
      "4b3b289cc50440df8b1afb61d37268c4",
      "3fe6c054b5c34e29ba317b4a40e71ac8",
      "57667c2dfccd48b1ab1d55f1b2617c96",
      "0db6c653b44a4aa2a6d7e73bef48d83f",
      "7cddbc630dfe4820b667b8c48f301c68",
      "a65a154bdd094521a96222b897e57579",
      "33a516fe74954f07959d0080aadb26fd",
      "fc8485b043e84a8997b2c292b6df68f7",
      "5cb1ae3d2553448e99c2e4007a149c67",
      "429a6cc2d3c3416087a3b9b53020f38b",
      "d2351d36d45a4017b47ebebab93d4c7e",
      "42a0556493b446d5baee85a87d0544a7",
      "23a89c10c37c4aac8034d129a39cde2f",
      "43f1da08d4624ba5a6e51ccc29ce72be",
      "d3ddf50e6c5f49998f7c6c16b3b86dea",
      "d8d7f68af61746ceabdceef19a450da9",
      "218cafc64ac64669a1fa105a62859a94",
      "4a91787c1e1e4910bef48956bb395669",
      "7c2037260b1e4dbfb00f79057963cc47",
      "f0c7ef79654c4eb0a6e9b4d1924d331a",
      "eb08eaa2227149868e370fcd1baee9e8",
      "391d2f0395434b08b5f6402539d38605",
      "00696aa32a184ad1a2a39fbfa2491b25",
      "d85893540e4e43778a3278f3c10af28f",
      "78d80ab0d2b5421e825c2320a6568799",
      "0554a01f014340c9b69b5b220b91bad7",
      "54ff65a7f05a41b9b289e7ef9651f3d0",
      "fcfbf87c56e14a49bbb5db6306332a2b",
      "54d61f1d74bd41a691663d24a926a5c5",
      "4f7cdf6e249d4a7cbdc15501d46f01b6",
      "f6729bc28f5f4a2f9db0ae8ea020547b",
      "a6c51cee44964a6b8ab2b0edbaababf7",
      "86d21c150907468d8010683001e6b15f",
      "9a2c055f5b004f7bad08cb3907ff8727",
      "207ffc9caf9344a891406d24894173a2",
      "e3e35ee725794e9bb63c7d0a2b1db61f",
      "f8681c927a4f4ef18278564ec1564aa9",
      "65d79418d13347a5b8c9943ca9dd85c6",
      "2a8b6106b19c429b952f23c3527eb57b",
      "cb194d979f144eb08f221afa9e362037",
      "bea1dd0915f54157a9bab3dc1d48a2d5",
      "694655294f6140259d97a94f25a11a42",
      "ba6dbb2e20eb496891f6d20c580ba10f",
      "a02affac88a34687b91af999d1522ca5",
      "b290baecb4624b90bf2e943f8da24d0f",
      "749e205fc7f54296a2c33eb0c300b3d3",
      "9e35c155000140c8bd7325d201e491be",
      "1abd97a0b1b644898d5dee4adf5a5cf7",
      "cb079cb5be98476a9ace329468835aaa",
      "62f30fd86a3040af9e1e50a744fedecf",
      "c68168c8fd744f779bf649ff9327d113",
      "88fbe989470848c4aebfb83fad7150bf",
      "7eeaaf335c414f48b00cf990b0052f7e",
      "8b792899bc1f4d35b3381a57bba58f7a",
      "9c35dc45dee64337bfecd4e08cc05fe7",
      "69b1dd40012a460ca7aec23bcf310096",
      "f86862b5f4d74e7290b01838c02fdfd9",
      "1cfd676bc9614f8699727ea0b50d4af5",
      "152b4a9a83cf4b2e85e2d24ae1810c80",
      "a03eb1f17f0142e6a7c7e1b82d09cef1",
      "0db85d01c47f46d9be4ae67fdf80ee86",
      "60601e706268456cbb5982a64fca99a8",
      "d6afd49ae0cf4e30922f0f17ab6f09f7",
      "7c63091d86c74c189f3eaa6c83992293",
      "95545e9931724c48a9c497cff7f1790b",
      "b732ad31fbbe49b29a9b7fc2b2cb33d6",
      "4a59de4170614bb081ed4d102ce0d863",
      "4c528cf4d9ec4f969a93d8637383d99d",
      "76677a2422214686ba9d726133a4f7d3",
      "c2a2d2dbad5f40c2a4b69c064aac64ee",
      "0c7488953dc04ba3b1017b1a325f3433",
      "5ebaec01e48e41c0965b66d7f8333398",
      "42cad6199ffd4cb39cb23f6ccdc4132a",
      "d0d8f6d92ff14972bcb014a50c4b5b2e",
      "26255396cdc64510827a09840cc66da7",
      "9fe90d2623774b8a93dcc50de46df8a9",
      "2bc0e88ddba5415d85dbdc428b037997",
      "4e02706ce5a248c79cce4cbd885a6a22",
      "1981c9cc748b44c4969517384a271514",
      "f86b69d1b77641b2909866e79150720b",
      "4ae2616b69aa4ed18b54a5051e3de808",
      "26045edef05e47cb9ac7e06f986a0d0e",
      "90e126c771d64406980f851666cc0b98",
      "4605cb43ed724105a02416ce8fcddba9",
      "c1f26a9cae4f4b93ac0b3fde74a4436a",
      "ae42647b80a248d78625122a301da66e",
      "f94786b76d5e4e4dbfbd3ba5628d2f4d",
      "c5852a9018ac4c7aa802a1c19dcfd622",
      "5b7b5e045a204beb827ea4937fbacf62",
      "ffe3e644237d4abc994ae0c0ff34f4db",
      "866128c41b964786a35fc034b60563ac",
      "0dafd1397ccb4d3eabcbab5484889afb",
      "5c6493e1f1944f51a56a24b5acd28888",
      "8c4f0cb9c35e4801b6db2c9a65fc0c6a",
      "0775a589731d44538c87d32a9a4b5276",
      "a0d569f672614a2b8124d9aeddbcf659",
      "09bbb1b34b3640f68dc4d196ab8dae10",
      "ce52c25bef1a45ec97ac193f0884bc4b",
      "f56957d0e0f94b5a96ecd9d02b934d23",
      "d80664da47fd4a1c8760facb3503ca95",
      "a6b6f83f969e473881721a7b9759d2ce",
      "3947b4e8b42b42ecb1cdf188fd49d90c",
      "1fca6ba5658f4480823c416ae811926d",
      "445fe3243443413f8137b0d26ef29178",
      "627f328ed2514e2eade01651e476b552",
      "f47faf1917234fda9fd6093c42a524f4",
      "4f40278313744f60a0488a7dfa4e8040",
      "06c39337f0a74b0ba403cee393a76f2b",
      "ee69b28204504abc9e76fd9e41d35e50",
      "fff8bfe53e974ed3b07e3aa51fc19a74",
      "5963c6d48bf44acd9b164a46a8d5b4a4",
      "f6c872fcb1e14d41aaf42328ccd7ffc3",
      "184158c8c79c47cfb7d43feed128b83f",
      "622cefb69fd74c6c8b628594cf8d01d2",
      "68714a32e0694ec6b64084b2761ed9fb",
      "d7d29a0b400e4aa2929289dc57a1877a",
      "67cbf098a4a145fe970d19e89570809c",
      "d66d65fcb1d54026a93ec0614b202633",
      "34ee4fc19c6748e0aef4d2a0d515b4e6",
      "fda5b992ca154a4eadd51e6a4b7c6755",
      "04dec988170d4b19a1decd4e6dafed86",
      "ff7ca05bb658466ca87c1c5e742f5a49",
      "a3153d4496c44a4a85e8defcaaf4440d",
      "1ac4fa799b55428194f4dd864613b926",
      "d4a72e48ca684c7da9de651b5bdfbc39",
      "25babf49cc8d46d49fec73bd77595278",
      "8ce96d7fe97e430eae6154a710519c40",
      "7951c74020664d8f984062053a37a104",
      "4e42c44e5e7f45cc896d12cd270fa895",
      "d418409893d3461f97da3c7f52f07b40",
      "d1ec6ab33ae949f6999a31567d65f7ca",
      "f59df93634114730a5f4b6a4300ec8e7",
      "73b26c39f4494987a7371be4c8feff99",
      "8159660c1fda40fe81f59ffc4db65677",
      "6f891ee1e6864e30bb189d26eeb0e58f",
      "f7bcb8c4244e4008a69d01c8ba20c19a"
     ]
    },
    "id": "RSNalRXZyTTk",
    "outputId": "a73ef1ca-eac1-4532-96c2-5e176e45fbda"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57df314d9974eff8c8c1264c6a66039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc1760009fb414981b7de9ebac6eb07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cddbc630dfe4820b667b8c48f301c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3.py:   0%|          | 0.00/73.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d7f68af61746ceabdceef19a450da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/16.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ff65a7f05a41b9b289e7ef9651f3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d79418d13347a5b8c9943ca9dd85c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb079cb5be98476a9ace329468835aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a03eb1f17f0142e6a7c7e1b82d09cef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c7488953dc04ba3b1017b1a325f3433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26045edef05e47cb9ac7e06f986a0d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6493e1f1944f51a56a24b5acd28888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "445fe3243443413f8137b0d26ef29178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68714a32e0694ec6b64084b2761ed9fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25babf49cc8d46d49fec73bd77595278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# 모델과 토크나이저를 로드합니다.\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdyYYS0E5fEU"
   },
   "source": [
    "모델과 토크나이저를 직접 사용할 수 있지만 `pipeline` 함수를 사용하는 것이 훨씬 쉽습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DiUi4Wu1FCyN",
    "outputId": "6614fcbe-5389-4e61-a0c4-56dc22ce5d21"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 파이프라인을 만듭니다.\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=500,\n",
    "    do_sample=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mD49kysT5mMY"
   },
   "source": [
    "마지막으로 프롬프트를 작성하고 모델에 주입합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hkR7LBmiyXmY",
    "outputId": "2add3f34-afef-49e4-844c-da45c040f01c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "`get_max_cache()` is deprecated for all Cache classes. Use `get_max_cache_shape()` instead. Calling `get_max_cache()` will raise error from v4.48\n",
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Why did the chicken join the band? Because it had the drumsticks!\n"
     ]
    }
   ],
   "source": [
    "# 프롬프트 (사용자 입력 / 쿼리)\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Create a funny joke about chickens.\"}\n",
    "]\n",
    "\n",
    "# 출력 생성\n",
    "output = generator(messages)\n",
    "print(output[0][\"generated_text\"])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
